---
title: "Trial analysis 4: predicting item variation"
author: "Mike"
date: "6/25/2022"
output: html_document
---

```{r setup, echo = FALSE}
# remotes::install_github("langcog/wordbankr")
library(wordbankr)
library(here)
library(tidyverse)
library(peekbankr)
library(lme4)
library(ggpmisc)
library(ggrepel)
library(ggthemes)
library(cowplot)

# Seed for random number generation
set.seed(42)
knitr::opts_chunk$set(cache.extra = knitr::rand_seed, cache = TRUE, 
                      message=FALSE, warning=FALSE, error=FALSE)

load(file = here("cached_intermediates","3A_d_acc.Rds"))
load(file = here("cached_intermediates","3A_mod_acc.Rds"))
load(file = here("cached_intermediates","3A_d_acc_bc.Rds"))
load(file = here("cached_intermediates","3A_mod_acc_bc.Rds"))
load(file = here("cached_intermediates","3B_d_rt.Rds"))
load(file = here("cached_intermediates","3B_mod_rt.Rds"))

```

# Compare to Wordbank AoAs

Load AoAs. 

```{r get_aoas, eval=FALSE}
items <- wordbankr::get_item_data(language = "English (American)") 

ws_data <- wordbankr::get_instrument_data(language = "English (American)", 
                                          form = "WS", 
                                          administration_info = TRUE, 
                                          item_info = TRUE)

ws_item_ids <- ws_data |>
  select(item_id, item_definition, item_kind) |>
  distinct()

wg_data <- wordbankr::get_instrument_data(language = "English (American)",
                                          form = "WG",
                                          administration_info = TRUE,
                                          item_info = TRUE)

wg_data_ws_ids <- wg_data |>
  select(-item_id) |>
  left_join(ws_item_ids)

wordbank_data <- bind_rows(ws_data, wg_data_ws_ids) |>
  mutate(form = "both") |>
  filter(item_kind == "word")

aoas <- wordbankr::fit_aoa(wordbank_data, 
                           measure = "produces", 
                           method = "glmrob",
                           age_min = 8, 
                           age_max = 36)

saveRDS(aoas, here("cached_intermediates","4A_aoas.rds"))
```

Load these from cache since it's time-consuming. 

```{r aoas}
aoas <- readRDS(here("cached_intermediates","4A_aoas.rds"))
```

Now let's look at the relationship between AoAs and accuracies. 

## Naive AoA-accuracy

What's the right metric to compare? Here are some ideas:

1. average accuracy (confounded with age and study)
2. accuracy random intercepts
3. predicted point at which accuracy is greater than XYZ%

Let's try each. First let's do average accuracy. 

```{r}
mdf <- d_acc |>
  group_by(target_label) |>
  summarise(avg_accuracy = mean(accuracy),
            avg_elogit = mean(elogit),
            n_trials = n()) |>
  inner_join(aoas |>
              ungroup() |>
              select(item_definition, aoa) |>
              rename(target_label = item_definition))

ggplot(mdf, aes(x = aoa, y = avg_accuracy)) + 
  geom_point(alpha = .5, aes(size = n_trials)) + 
  geom_smooth(method = "lm") + 
  ggpmisc::stat_correlation() + 
  ggrepel::geom_label_repel(aes(label = target_label))
```
There's a correlation, but it goes in the WRONG direction! 

Presentation Plot

```{r}
ggplot(mdf, aes(x = aoa, y = avg_accuracy)) + 
  geom_point(alpha = .5, aes(size = n_trials)) + 
  geom_smooth(method = "lm") + 
  ggpmisc::stat_correlation(small.r=TRUE,size=8) + 
  ggrepel::geom_label_repel(aes(label = target_label),max.overlaps=7)+
  theme_cowplot(font_size=20)+
  xlab("Age of Acquisition (Wordbank estimates)")+
  ylab("Average Accuracy")+
  scale_size_continuous(name="# trials")+
  theme(legend.position=c(0.1,0.2))
ggsave(here(figure_path,"aoa_correlation.png"),width=10,height=6,dpi=600)
```


```{r}
ggplot(filter(mdf, n_trials > 200), 
       aes(x = aoa, y = avg_accuracy)) + 
  geom_point(alpha = .5, aes(size = n_trials)) + 
  geom_smooth(method = "lm") + 
  ggpmisc::stat_correlation() + 
  ggrepel::geom_label_repel(aes(label = target_label))
```
The correlation only gets stronger when we subset to items about which we have a lot of data. What it looks like is that we have some serious confounding such that the lower-accuracy items are easier items used in studies with younger kids. 

Let's try methods 2 and 3.

```{r}
ranefs <- tibble(ranef(mod_acc)$target_label) |>
  rename(intercept = `(Intercept)`,
         slope = `log_age_centered`)
ranefs$target_label <- rownames(ranef(mod_acc)$target_label) 

mdf <- left_join(mdf, ranefs)
```

## Model-based comparison to AoA
Extract "AoAs" from predicted curves. We're going to get the point at which a word crosses the elogit = 1 line as "the age of acquisition" - approx the point when the proportion accuracy hits 75%. We'll also look at the elogit value at age 36 months as different proxy. (These points are marked by the two red lines below). 

```{r}
words <- d_acc |>
  group_by(target_label) |> 
  count() 
  
hf_words = words |>
  filter(n > 200)

preds <- expand_grid(
  animate_target = FALSE, 
  animate_distractor = FALSE, 
  log_age_centered = seq(min(d_acc$log_age_centered),
                max(d_acc$log_age_centered), .1),
  target_label = unique(d_acc$target_label)) |>
  filter(target_label %in% hf_words$target_label)

preds <- preds |>
  mutate(.pred = predict(mod_acc, 
                         type = "response",
                         re.form = ~  (log_age_centered | target_label), 
                         newdata = preds), 
         age = exp(log_age_centered + mean(d_acc$log_age)))

ggplot(filter(preds, target_label %in% hf_words$target_label),
       aes(x = age, y = .pred, col = target_label)) + 
  geom_line() + 
  geom_hline(lty = 2, yintercept = 0) + 
  geom_hline(lty = 3, yintercept = 1, col = "red") + 
  geom_vline(lty = 3, xintercept = 36, col = "red") + 
  xlab("Age (months)") + 
  ggthemes::theme_few()
```

Now join in these curves and plot. 

```{r}         
mdf <- left_join(mdf, 
                 preds |>
                   group_by(target_label) |>
                   summarise(mod_aoa = age[.pred > 1][1],
                             mod_elogit_36_mo = .pred[age > 36][1]))

mdf_long <- mdf |> 
  pivot_longer(cols = -c("target_label", "aoa", "n_trials"), 
               names_to = "predictor", 
               values_to = "value")

ggplot(mdf_long, 
       aes(x = aoa, y = value)) + 
  geom_point(alpha = .5, aes(size = n_trials)) + 
  geom_smooth(method = "lm") + 
  ggpmisc::stat_correlation() + 
  # ggrepel::geom_label_repel(aes(label = target_label)) + 
  facet_wrap(~predictor, scales="free_y")
```

Ugh. Surprising that these are not more related. Let's filter down to the words about which we have any data. 


```{r}
ggplot(filter(mdf_long, n_trials > 200),
       aes(x = aoa, y = value)) + 
  geom_point(alpha = .5, aes(size = n_trials)) + 
  geom_smooth(method = "lm") + 
  facet_wrap(~predictor, scales="free_y") + 
  ggpmisc::stat_correlation() + 
  # ggrepel::geom_label_repel(aes(label = target_label)) + 
  xlab("Wordbank AoA") + 
  ylab("Peekbank model measure")
```

So going through these:

* `avg_accuracy` goes the opposite direction of what we wanted -- accuracy higher for later aquired words. probably due to confounding as discussed above. 
* `intercept` and `slope` - these are the `target_word` random effects from the model. they should be higher for earlier acquired words. these also appear to go in the opposite direction from what we'd predict. 
* `mod_aoa` - this should be the same as wordbank AoA - in other words, a positive relation. Again, appears negative. 
* `mod_elogit_36_mo` this should be another measure of accuracy, so *higher* for low AoA words. again, goes in the wrong direction. 

In sum, ALL of these go in the wrong direction. What gives? Let's zoom in on model AoA. 

```{r}
ggplot(filter(mdf_long, predictor == "mod_aoa", n_trials > 200),
       aes(x = aoa, y = value)) + 
  geom_point(alpha = .5, aes(size = n_trials)) + 
  geom_smooth(method = "lm") + 
  ggpmisc::stat_correlation() + 
  ggrepel::geom_label_repel(aes(label = target_label)) +
  xlab("Wordbank AoA") + 
  ylab("Peekbank model measure")
```

What we see is that `ball` is consistently bad, as we observed throughout. `dog` also comes out surprisingly bad! We do see that book, baby, car are more easily recognized however. 

In sum, we're not seeing ANY successes in linking peekbank to wordbank.

## Baseline corrected accuracy and AoA

```{r}
words <- d_acc_bc |>
  group_by(target_label) |> 
  count() 
  
hf_words = words |>
  filter(n > 200)

preds <- expand_grid(
  animate_target = FALSE, 
  animate_distractor = FALSE, 
  log_age_centered = seq(min(d_acc_bc$log_age_centered),
                max(d_acc_bc$log_age_centered), .1),
  target_label = unique(d_acc_bc$target_label))

preds <- preds |>
  mutate(.pred = predict(lmm_fit_bc, 
                         type = "response",
                         re.form = ~  (log_age_centered | target_label), 
                         newdata = preds), 
         age = exp(log_age_centered + mean(d_acc$log_age)))

ggplot(filter(preds, target_label %in% hf_words$target_label),
       aes(x = age, y = .pred, col = target_label)) + 
  geom_line() + 
  geom_hline(lty = 2, yintercept = 0) + 
  geom_hline(lty = 3, yintercept = 1, col = "red") + 
  geom_vline(lty = 3, xintercept = 36, col = "red") + 
  xlab("Age (months)") + 
  ggthemes::theme_few()
```

```{r}         
mdf <- left_join(mdf, 
                 preds |>
                   group_by(target_label) |>
                   summarise(mod_aoa_bc = age[.pred > 1][1],
                             mod_elogit_36_mo_bc = .pred[age > 36][1]))

mdf_long <- mdf |> 
  pivot_longer(cols = -c("target_label", "aoa", "n_trials"), 
               names_to = "predictor", 
               values_to = "value")

ggplot(mdf_long, 
       aes(x = aoa, y = value)) + 
  geom_point(alpha = .5, aes(size = n_trials)) + 
  geom_smooth(method = "lm") + 
  ggpmisc::stat_correlation() + 
  # ggrepel::geom_label_repel(aes(label = target_label)) + 
  facet_wrap(~predictor, scales="free_y")
```

```{r}
ggplot(filter(mdf_long, predictor == "mod_aoa_bc"),
       aes(x = aoa, y = value)) + 
  geom_point(alpha = .5, aes(size = n_trials)) + 
  geom_smooth(method = "lm") + 
  ggpmisc::stat_correlation() + 
  ggrepel::geom_label_repel(aes(label = target_label)) +
  xlab("Wordbank AoA") + 
  ylab("Peekbank baseline-corrected model measure")
```

## RT to AoA

Let's extract our RT summaries as RT predicted at 36 months and also AoA at 750ms.

```{r}
words <- d_rt_dt |>
  group_by(target_label) |> 
  count() 
  
hf_words = words |>
  filter(n > 200)

preds <- expand_grid(
  log_age_centered = seq(min(d_rt_dt$log_age_centered),
                max(d_rt_dt$log_age_centered), .1),
  target_label = unique(d_rt_dt$target_label))

preds <- preds |>
  mutate(.pred = predict(lmm_fit_rt, 
                         type = "response",
                         re.form = ~  (log_age_centered | target_label), 
                         newdata = preds), 
         age = exp(log_age_centered + mean(d_acc$log_age)))

ggplot(filter(preds, target_label %in% hf_words$target_label),
       aes(x = age, y = .pred, col = target_label)) + 
  geom_line() + 
  geom_hline(lty = 3, yintercept = log(750), col = "red") + 
  geom_vline(lty = 3, xintercept = 36, col = "red") + 
  xlab("Age (months)") + 
  ggthemes::theme_few()
```

Add measures. 

```{r}         
mdf <- left_join(mdf, 
                 preds |>
                   group_by(target_label) |>
                   summarise(mod_aoa_rt = age[.pred < log(750)][1],
                             mod_rt_36_mo = .pred[age > 36][1]))
```

Plot. 

```{r}
mdf_long <- mdf |> 
  pivot_longer(cols = -c("target_label", "aoa", "n_trials"), 
               names_to = "predictor", 
               values_to = "value")

ggplot(mdf_long, 
       aes(x = aoa, y = value)) + 
  geom_point(alpha = .5, aes(size = n_trials)) + 
  geom_smooth(method = "lm") + 
  ggpmisc::stat_correlation() + 
  # ggrepel::geom_label_repel(aes(label = target_label)) + 
  facet_wrap(~predictor, scales="free_y")
```
Subset to high frequency words. 

```{r}
ggplot(filter(mdf_long, 
              target_label %in% words$target_label[words$n > 100]), 
       aes(x = aoa, y = value)) + 
  geom_point(alpha = .5, aes(size = n_trials)) + 
  geom_smooth(method = "lm") + 
  ggpmisc::stat_correlation() + 
  facet_wrap(~predictor, scales="free_y") + 
  xlab("Wordbank AoA (months)") + 
  ylab("Predictor value")
```


```{r}
ggplot(filter(mdf_long, predictor == "mod_rt_36_mo", 
              target_label %in% words$target_label[words$n > 100]),
       aes(x = aoa, y = value)) + 
  geom_point(alpha = .5, aes(size = n_trials)) + 
  geom_smooth(method = "lm") + 
  ggpmisc::stat_correlation() + 
  ggrepel::geom_label_repel(aes(label = target_label)) +
  xlab("Wordbank AoA") + 
  ylab("Peekbank model-derived log RT at 36mo")
```